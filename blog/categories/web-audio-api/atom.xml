<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Web Audio API | Codaholic]]></title>
  <link href="http://srikumarks.github.com/blog/categories/web-audio-api/atom.xml" rel="self"/>
  <link href="http://srikumarks.github.com/"/>
  <updated>2013-03-13T12:13:09+05:30</updated>
  <id>http://srikumarks.github.com/</id>
  <author>
    <name><![CDATA[Srikumar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Taming the ScriptProcessorNode]]></title>
    <link href="http://srikumarks.github.com/blog/2013/01/30/taming-the-scriptprocessornode/"/>
    <updated>2013-01-30T21:20:00+05:30</updated>
    <id>http://srikumarks.github.com/blog/2013/01/30/taming-the-scriptprocessornode</id>
    <content type="html"><![CDATA[<p>The <a href="http://www.w3.org/TR/webaudio">Web Audio API</a> provides graph based API for audio generation and
processing primitives with a focus on high performance and low latency. For
custom processing that is not covered by the builtin native audio nodes, it
provides a <a href="http://www.w3.org/TR/webaudio/#ScriptProcessorNode">ScriptProcessorNode</a> whose processing is determined by a Javascript
function. Though the <a href="http://www.w3.org/TR/webaudio/#ScriptProcessorNode">ScriptProcessorNode</a> is presented like any other node
type by the API, its behaviour differs from the other native nodes in some
fundamental ways. This post examines some of these differences using a simple
chime model as the use case, and derives some suggestions for the <a href="http://www.w3.org/TR/webaudio">Web Audio API</a>
specification.</p>

<!-- more -->


<h4>Contents</h4>

<ol>
<li><a href="#simple-chime-model">A simple chime model</a></li>
<li><a href="#abstracting-chime-model">Abstracting the chime model</a></li>
<li><a href="#replacing-gain-node-with-scriptprocessornode">Replacing the gain node with a ScriptProcessorNode</a>

<ol>
<li><a href="#vanishing-script-node">Problem 1: The vanishing script node</a></li>
<li><a href="#eternal-script-node">Problem 2: The eternal script node</a></li>
</ol>
</li>
<li><a href="#replacing-oscillator-with-scriptprocessornode">Replacing the oscillator with a ScriptProcessorNode</a></li>
<li><a href="#accounting-for-tail-time">Accounting for tail time</a></li>
<li><a href="#reflections-on-api">Reflections on the API</a></li>
<li><a href="#concluding-suggestions">Concluding suggestions</a></li>
<li><a href="#stellers-jsnode-model">PS: Steller's jsnode model</a></li>
</ol>


<h2><a name="simple-chime-model"></a>A simple chime model</h2>

<p>Let's consider a simple kind of sound - a "chime", a decaying sinusoid
oscillating at a given frequency. This can be implemented using an
<a href="http://www.w3.org/TR/webaudio/#OscillatorNode">OscillatorNode</a> and a <a href="http://www.w3.org/TR/webaudio/#GainNode">GainNode</a> as follows -</p>

<p><img src="/images/osc-gain.svg"></p>

<p><code>js
var AC = new webkitAudioContext();
var osc = AC.createOscillator();
osc.frequency.value = 880.0;
var gain = AC.createGainNode();
osc.connect(gain);
gain.connect(AC.destination);
gain.gain.value = 0.25;
gain.gain.setTargetAtTime(0.0, AC.currentTime, 2.0);
osc.start(AC.currentTime + 5.0);
osc.stop(AC.currentTime + 15.0);
</code></p>

<p>The above code produces a single chime that lasts for about 10 seconds, with a
decay time constant of 2 seconds. Though this is not very useful as it stands,
it helps to illustrate a couple of aspects of nodes in the <a href="http://www.w3.org/TR/webaudio">Web Audio API</a>.</p>

<p>First, we see two types of nodes being used -- a "source" node (the oscillator)
which generates a signal without needing an input, and a "processor" node (the
gain) which takes an input signal, does something with it and sends a modified
signal to its output.</p>

<p>Second, we see a time limited triggering of the <a href="http://www.w3.org/TR/webaudio/#OscillatorNode">OscillatorNode</a>. The node is
triggered 5 seconds into the future and is stopped 10 seconds after it starts.
The way the <a href="http://www.w3.org/TR/webaudio">Web Audio API</a> is designed, once the oscillator node has stopped,
it becomes rather useless and needs to be discarded. This is because start/stop
can be used only once on source nodes. Therefore when using an <a href="http://www.w3.org/TR/webaudio/#OscillatorNode">OscillatorNode</a>
as in this example, the references to <code>osc</code> and <code>gain</code> are no longer necessary
and we can add the following lines at the end of the above code block.</p>

<p><code>js
osc = null;
gain = null;
</code></p>

<p>With no references holding the oscillator and gain nodes from garbage collection,
one might think that they might be destroyed soon after the references are
given up, before the oscillator gets a chance to generate any sound. Fortunately,
the oscillator holds a reference to itself until its stop time is reached,
after which the reference is released and the subgraph between the source and the
context destination is destroyed. This behaviour of native source nodes is
documented in the <a href="http://www.w3.org/TR/webaudio/#DynamicLifetime">Dynamic Lifetime</a> section of the <a href="http://www.w3.org/TR/webaudio">Web Audio API</a> documentation.</p>

<h2><a name="abstracting-chime-model"></a>Abstracting the chime model</h2>

<p>The chime model described in the previous section only plays one chime. This is
practically useless in the real world. A more useful incarnation of the chime model
would permit us to trigger a chime at any time we want and at any frequency
we want as well. The model manages the nodes necessary for its function
purely internally.</p>

<p><img src="/images/chime.svg"></p>

<p>This is easily encapsulated as a function --</p>

<p>``` js
var AC = new webkitAudioContext(); // We'll assume this here onwards.</p>

<p>function chime(freq, output) {</p>

<pre><code>var stopTime = AC.currentTime + 10.0;
var osc = AC.createOscillator();
osc.frequency.value = freq || 880.0;
var gain = AC.createGainNode();
osc.connect(gain);
gain.connect(output || AC.destination);
gain.gain.value = 0.25;
gain.gain.setTargetAtTime(0.0, AC.currentTime, 2.0);
osc.start(AC.currentTime);
osc.stop(AC.currentTime + 10.0);
// References to osc and gain are given up
// upon return from chime().
</code></pre>

<p>}
```</p>

<h2><a name="replacing-gain-node-with-scriptprocessornode"></a>Replacing the gain node with a ScriptProcessorNode</h2>

<p>Now let's consider what happens if we try to replace the gain node's behaviour
(limited to this example) using a <a href="http://www.w3.org/TR/webaudio/#ScriptProcessorNode">ScriptProcessorNode</a>.</p>

<p>``` js <a name="chime_jsgain">chime_jsgain</a> A straightforward replacement of the gain node with a script node.
var AC = new webkitAudioContext();</p>

<p>function chime_jsgain(freq, output) {</p>

<pre><code>var osc = AC.createOscillator();
var stopTime = AC.currentTime + 10.0;
osc.frequency.value = freq || 880.0;
var gain = AC.createScriptProcessor(1024, 1, 1);
gain.onaudioprocess = (function () {
    var amplitude = 0.25;
    var decay = Math.exp(- 1.0 / (2.0 * AC.sampleRate));
    return function (event) {
        var i, N, inp, out;
        inp = event.inputBuffer.getChannelData(0);
        out = event.outputBuffer.getChannelData(0);
        for (i = 0, N = out.length; i &lt; N; ++i, amplitude *= decay) {
            out[i] = amplitude * inp[i];
        }
    };
}());
osc.connect(gain);
gain.connect(output || AC.destination);
osc.start(AC.currentTime);
osc.stop(stopTime);
</code></pre>

<p>}
```</p>

<h3><a name="vaninshing-script-node"></a>Problem 1: The vanishing script node</h3>

<p>If you try to make a chime using <a href="#chime_jsgain">chime_jsgain</a>, you'll find
that the sound stops abruptly well before the 10 seconds duration given.  This
is because the script node is garbage collected almost immediately.  This is
a <a href="https://code.google.com/p/chromium/issues/detail?id=82795">WebKit implementation bug</a>. The oscillator node, which has a
persistent reference till stop time, holds a reference to the script node
through its output, and yet the script node is garbage collected. A known
workaround for this bug is to maintain a <em>global</em> reference to the script node.
For this, we can use the following simple scheme --</p>

<p><em>edit</em>: Added link to issue.</p>

<p>``` js <a name="keep">keep</a> Preserving script nodes.
var scriptNodes = {};
var keep = (function () {</p>

<pre><code>var nextNodeID = 1;
return function (node) {
    node.id = node.id || (nextNodeID++);
    scriptNodes[node.id] = node;
    return node;
};
</code></pre>

<p>}());
```</p>

<p>Using the <code>keep</code> utility, we can now rewrite <code>chime_jsnode</code> as --</p>

<p>``` js Keeping around a global reference to the script node.
function chime_jsgain(freq, output) {</p>

<pre><code>// ...
var gain = keep(AC.createScriptProcessor(1024, 1, 1));
// ...
</code></pre>

<p>}
```</p>

<p>This will result in the script node being preserved during the course of
the chime.</p>

<h3><a name="eternal-script-node"></a>Problem 2: The eternal script node</h3>

<p>With the modifications of the preceding section, the oscillator node will
disappear after 10 seconds but the script node will persist and continue to be
processed. To prevent this, we make arrangement for the script node to be
removed from the graph and for its global reference to be dropped once it has
processed enough samples.</p>

<p>``` js <a name="drop">drop</a> Dropping the global reference to a node.
function drop(node) {</p>

<pre><code>delete scriptNodes[node.id];
return node;
</code></pre>

<p>}
```</p>

<p>We incorporate the new <code>drop</code> function into <code>chime_jsnode</code> as follows --</p>

<p>``` js A script implementation of gain node with proper end of life management.
function chime_jsgain(freq, output) {</p>

<pre><code>var osc = AC.createOscillator();
var stopTime = AC.currentTime + 10.0;
osc.frequency.value = freq || 880.0;
var gain = keep(AC.createScriptProcessor(1024, 1, 1));
gain.onaudioprocess = (function () {
    var amplitude = 0.25;
    var decay = Math.exp(- 1.0 / (2.0 * AC.sampleRate));
    var stopTime_samples = Math.ceil(AC.sampleRate * stopTime);
    var finished = false;
    return function (event) {
        var i, N, inp, out;

        if (finished) {
            return; // Don't do anything after stopTime has elapsed.
        }

        inp = event.inputBuffer.getChannelData(0);
        out = event.outputBuffer.getChannelData(0);

        // Limit the number of samples we compute.
        var now_samples = Math.floor(AC.sampleRate * AC.currentTime);
        N = Math.min(out.length, stopTime_samples - now_samples);

        for (i = 0; i &lt; N; ++i, amplitude *= decay) {
            out[i] = amplitude * inp[i];
        }

        if (N &lt; out.length) {
            // Reached end time before end of buffer.
            finished = true;
            setTimeout(function () {
                drop(gain);
                osc.disconnect();
                gain.disconnect();
            }, 0);
        }
    };
}());
osc.connect(gain);
gain.connect(output || AC.destination);
osc.start(AC.currentTime);
osc.stop(stopTime);
</code></pre>

<p>}
```</p>

<p>We now have a script node based implementation that works like the native
implementation in all respects. This kind of "stop time" behaviour can be
lifted into a separate function that transforms a <code>function (event, toSamp) {...}</code>
into an <code>onaudioprocess</code> handler.</p>

<p>``` js <a name="scriptWithStopTime">scriptWithStopTime</a> End of life management of script nodes.
function scriptWithStopTime(stopTime, handler) {</p>

<pre><code>var node = keep(AC.createScriptProcessor(1024, 1, 1));
var stopTime_samples = Math.ceil(AC.sampleRate * stopTime);
var finished = false;
node.onaudioprocess = function (event) {
    if (finished) {
        return;
    }

    var t = Math.floor(AC.sampleRate * AC.currentTime);
    var toSamp = Math.min(event.outputBuffer.length, stopTime_samples - t);

    handler(event, toSamp);

    if (toSamp &lt; event.outputBuffer.length) {
        finished = true;
        setTimeout(function () {
            drop(event.node);
            event.node.disconnect();
        }, 0);
    }
};
return node;
</code></pre>

<p>}
```</p>

<p>Using <a href="#scriptWithStopTime">scriptWithStopTime</a>, we can now rewrite <code>chime_jsgain</code> as --</p>

<p>``` js
function chime_jsgain(freq, output) {</p>

<pre><code>var osc = AC.createOscillator();
var stopTime = AC.currentTime + 10.0;
osc.frequency.value = freq || 880.0;
var gain = scriptWithStopTime(stopTime, (function () {
    var amplitude = 0.25;
    var decay = Math.exp(- 1.0 / (2.0 * AC.sampleRate));
    return function (event, N) {
        var i, inp, out;
        inp = event.inputBuffer.getChannelData(0);
        out = event.outputBuffer.getChannelData(0);
        for (i = 0; i &lt; N; ++i, amplitude *= decay) {
            out[i] = amplitude * inp[i];
        }
    };
}()));
osc.connect(gain);
gain.connect(output || AC.destination);
osc.start(AC.currentTime);
osc.stop(stopTime);
</code></pre>

<p>}
```</p>

<h2><a name="replacing-oscillator-with-scriptprocessornode"></a>Replacing the oscillator with a ScriptProcessorNode</h2>

<p>Now, let's consider what happens if we try to implement the <a href="http://www.w3.org/TR/webaudio/#OscillatorNode">OscillatorNode</a>
(limited to this example) using a <a href="http://www.w3.org/TR/webaudio/#ScriptProcessorNode">ScriptProcessorNode</a>. We can use
<a href="#scriptWithStopTime">scriptWithStopTime</a> to take a first shot at it.
While we're there, we'll also generalize the chime model to take a time
at which to trigger the chime.</p>

<p>``` js
function chimeJS(t, freq, output) {</p>

<pre><code>freq = freq || 880.0;
t = Math.max(t || 0.0, AC.currentTime);
var stopTime = t + 10.0;    
var osc = scriptWithStopTime(stopTime, (function () {
    var phi = 0, dphi = 2.0 * Math.PI * freq / AC.sampleRate;
    return function (event, N) {
        var i, out;
        out = event.outputBuffer.getChannelData(0);
        for (i = 0; i &lt; N; ++i, phi += dphi) {
            out[i] = Math.sin(phi);
        }
    };
}()));
var gain = AC.createGainNode();
gain.gain.value = 0.0;
gain.gain.setValueAtTime(0.25, t);
gain.gain.setTargetAtTime(0.0, t, 2.0);
osc.connect(gain);
gain.connect(output || AC.destination);
</code></pre>

<p>}
```</p>

<p>Exposing the start time makes obvious a few design flaws --</p>

<ol>
<li><p>If you schedule a chime into the future instead of "right now",
the script node oscillator will keep running from "right now" until
the end. The period from "now" to the scheduled start time is all
wasted computation.</p></li>
<li><p>The node responsible for the chime starting on time is the <code>gain</code>
node. Since the oscillator is continuously running, the phase at
which the oscillator begins will depend on the time passed in,
but ideally we want the oscillator to start with phase 0 when
the chime starts .. and we want it to be sample accurate.</p></li>
</ol>


<p>To solve the wasted computation problem, we can make the <code>onaudioprocess</code>
be a no-op until the start time. This is best done by writing a
<code>scriptWithStartStopTime</code> as we did with <code>scriptWithStopTime</code>.</p>

<p>``` js <a name="scriptWithStartStopTime2">scriptWithStartStopTime</a> Removing wasted computation.
function scriptWithStartStopTime(startTime, stopTime, handler) {</p>

<pre><code>console.assert(stopTime &gt;= startTime);
var node = keep(AC.createScriptProcessor(1024, 1, 1));
var startTime_samples = Math.floor(AC.sampleRate * startTime);
var stopTime_samples = Math.ceil(AC.sampleRate * stopTime);
var finished = false;
node.onaudioprocess = function (event) {
    if (finished) {
        return;
    }

    var t = Math.floor(AC.currentTime * AC.sampleRate);
    var fromSamp = Math.max(0, startTime_samples - t);

    if (fromSamp &gt;= event.outputBuffer.length) {
        // Not started yet.
        return;
    }

    var toSamp = Math.min(event.outputBuffer.length, stopTime_samples - t);

    // Handler signature changed to include both start and stop indices.
    handler(event, fromSamp, toSamp);

    if (toSamp &lt; event.outputBuffer.length) {
        finished = true;
        setTimeout(function () {
            drop(event.node);
            event.node.disconnect();
        }, 0);
    }
};
return node;
</code></pre>

<p>}
```</p>

<p>The above version saves <em>some</em> computation but not all. The JS node does not
need to receive any callbacks whatsoever until it is time to start generating
samples. To achieve this, we need to schedule the node to connect and start
just in time, say 0.1 seconds before the scheduled start time. To do this,
we need to generalize <code>scriptWithStartStopTime</code> to work with the nodes
to which the script node is expected to connect.</p>

<p>``` js <a name="scriptWithStartStopTime2">scriptWithStartStopTime</a> Delayed node setup.
function scriptWithStartStopTime(input, output, startTime, stopTime, handler) {</p>

<pre><code>startTime = Math.max(startTime, AC.currentTime);
stopTime = Math.max(stopTime, AC.currentTime);
console.assert(stopTime &gt;= startTime);

var kBufferLength = 512; // samples
var prepareAheadTime = 0.1; // seconds

var startTime_samples = Math.floor(AC.sampleRate * startTime);
var stopTime_samples = Math.ceil(AC.sampleRate * stopTime);
var finished = false;

function onaudioprocess(event) {
    if (finished) { return; }

    var t = Math.floor(AC.currentTime * AC.sampleRate);
    var fromSamp = Math.max(0, startTime_samples - t);

    if (fromSamp &gt;= event.outputBuffer.length) {
        return; // Not started yet.
    }

    var toSamp = Math.min(event.outputBuffer.length, stopTime_samples - t);

    // Handler signature changed to include both start and stop indices.
    handler(event, fromSamp, toSamp);

    if (toSamp &lt; event.outputBuffer.length) {
        finished = true;
        setTimeout(function () {
            drop(event.node);
            input &amp;&amp; input.disconnect();
            event.node.disconnect();
        }, 0);
    }
}

function prepareNode() {
    var node = keep(AC.createScriptProcessor(kBufferLength, 1, 1));
    node.onaudioprocess = onaudioprocess;

    // Setup the necessary connections.
    input &amp;&amp; input.connect(node);
    output &amp;&amp; node.connect(output);
}

var dt = startTime - AC.currentTime;
if (dt &lt;= prepareAheadTime) {
    prepareNode();
} else {
    setTimeout(prepareNode, Math.floor(1000 * dt));
}

return node;
</code></pre>

<p>}
```</p>

<p>We can use <code>scriptWithStartStopTime</code> to include such dynamically determined
source or processing nodes within a subgraph ... except when two such nodes
need to be connected to each other and both remain unrealized for a while. In
such cases, we can use an intermediate unity gain node for simplicity. Here
then is our final chime model with a js node for the gain or the oscillator.</p>

<p>``` js
function chime_jsosc(t, freq, output) {</p>

<pre><code>freq = freq || 880.0;
t = Math.max(t || 0.0, AC.currentTime);
var stopTime = t + 10.0;   

var gain = AC.createGainNode();
gain.gain.value = 0.0;
gain.gain.setValueAtTime(0.25, t);
gain.gain.setTargetAtTime(0.0, t, 2.0);
gain.connect(output || AC.destination);

var osc = scriptWithStartStopTime(null, gain, t, stopTime, (function () {
    var phi = 0, dphi = 2.0 * Math.PI * freq / AC.sampleRate;
    return function (event, fromSamp, toSamp) {
        var i, out;
        out = event.outputBuffer.getChannelData(0);
        for (i = fromSamp; i &lt; toSamp; ++i, phi += dphi) {
            out[i] = Math.sin(phi);
        }
    };
}()));
</code></pre>

<p>}</p>

<p>function chime_jsgain(t, freq, output) {</p>

<pre><code>freq = freq || 880.0;
t = Math.max(t || 0.0, AC.currentTime);
output = output || AC.destination;
var stopTime = t + 10.0;   

var osc = AC.createOscillator();
osc.frequency.value = freq;

var gain = scriptWithStartStopTime(osc, output, t, stopTime, (function () {
    var amplitude = 0.25;
    var decay = Math.exp(- 1.0 / (2.0 * AC.sampleRate));
    return function (event, fromSamp, toSamp) {
        var i, inp, out;
        inp = event.inputBuffer.getChannelData(0);
        out = event.outputBuffer.getChannelData(0);
        for (i = fromSamp; i &lt; toSamp; ++i, amplitude *= decay) {
            out[i] = amplitude * inp[i];
        }
    };
}()));

osc.start(t);
osc.stop(stopTime);
</code></pre>

<p>}  <br/>
```</p>

<h2><a name="accounting-for-tail-time"></a>Accounting for tail time</h2>

<p>The gain node is simple in that it produces one output sample for each input
sample it receives on its input pin. Other node types, especially filter and
convolution nodes, may "tail off" well after the input to these nodes has
ceased. In other words, the true stop time of a node at which the node is
free to be garbage collected is at the end of such a tail time, which may
be only known when the node is running.</p>

<p>A simple way to account for this is to have the handler passed to
<code>scriptWithStartStopTime</code> use the <code>toSamp</code> argument only for information and
return the number of samples it actually produced. If the handler has produced
samples up to the buffer's capacity, then it cannot be stopped.  If it stopped
somewhere before the end of the buffer, then it can be taken to be finished and
cleanup can be triggered. This logic can be expressed in a modified
<code>scriptWithStartStopTime</code> as shown below --</p>

<p>``` js <a name="final-scriptWithStartStopTime">scriptWithStartStopTime</a> Supporting tail time.
function scriptWithStartStopTime(input, output, startTime, stopTime, handler) {</p>

<pre><code>startTime = Math.max(startTime, AC.currentTime);
stopTime = Math.max(stopTime, AC.currentTime);
console.assert(stopTime &gt;= startTime);

var kBufferLength = 512; // samples
var prepareAheadTime = 0.1; // seconds

var startTime_samples = Math.floor(AC.sampleRate * startTime);
var stopTime_samples = Math.ceil(AC.sampleRate * stopTime);
var finished = false;

function onaudioprocess(event) {
    if (finished) { return; }

    var t = Math.floor(AC.currentTime * AC.sampleRate);
    var fromSamp = Math.max(0, startTime_samples - t);

    if (fromSamp &gt;= event.outputBuffer.length) {
        return; // Not started yet.
    }

    var toSamp = Math.min(event.outputBuffer.length, stopTime_samples - t);

    // Return value of handler is used to decide when to stop. The handler is
    // required to produce as many samples as possible. If it still can't fill
    // up the buffer, it is deemed to have finished.
    var samplesProduced = handler(event, fromSamp, toSamp);

    if (fromSamp + samplesProduced &lt; event.outputBuffer.length) {
        finished = true;
        setTimeout(function () {
            drop(event.node);
            input &amp;&amp; input.disconnect();
            event.node.disconnect();
        }, 0);
    }
}

function prepareNode() {
    var node = keep(AC.createScriptProcessor(kBufferLength, 1, 1));
    node.onaudioprocess = onaudioprocess;

    // Setup the necessary connections.
    input &amp;&amp; input.connect(node);
    output &amp;&amp; node.connect(output);
}

var dt = startTime - AC.currentTime;
if (dt &lt;= prepareAheadTime) {
    prepareNode();
} else {
    setTimeout(prepareNode, Math.floor(1000 * dt));
}

return node;
</code></pre>

<p>}
```</p>

<h2><a name="reflections-on-api"></a>Reflections on the API</h2>

<p>The <a href="#final-scriptWithStartStopTime">final form of scriptWithStartStopTime</a>
expresses functionality that is essential to the use of script nodes as
algorithmic signal sources and signal processors that can be scheduled
to sample accuracy. Although this function adds the required functionality,
the <a href="http://www.w3.org/TR/webaudio">Web Audio API</a> would be better off with a script node type whose
lifetime can be managed just like the native nodes and suppor the
dynamic behaviour available with the native nodes.</p>

<p>Not having it builtin results in an inconsistency that is awkward to
work around - the fact that <code>start(t)</code> and <code>stop(t)</code> methods added in pure
Javascript are not only necessary for script nodes that are pure signal
generators, but also for signal processors. This is because a script node might
otherwise end up wasting compute cycles either idling or computing audio that
is going to be discarded by the rest of the chain. A <code>stop(t)</code> method is
necessary for such processor nodes because the <a href="http://www.w3.org/TR/webaudio">Web Audio API</a> does not
currently provide any notification mechanisms for monitoring connections to a
node's input and output so that processor nodes can self destruct when their
inputs die.</p>

<h2><a name="concluding-suggestions"></a>Concluding suggestions</h2>

<p>The use case worked through in this post demonstrates how abstractions built on
other nodes do not extend to script nodes without special considerations. The
two kinds of usages for script nodes discussed here -- sources and signal
processors -- are common scenarios. Having the following features built into
the <a href="http://www.w3.org/TR/webaudio/#ScriptProcessorNode">ScriptProcessorNode</a> helps avoid the problems that crop up in
straightfoward usage of script nodes.</p>

<ol>
<li>Permit creation of script nodes without inputs. This better models source
nodes. Passing 0 for "number of input channels" may be enough at the API
level.</li>
<li>Add <code>start(t)</code> and <code>stop(t)</code> methods to permit script nodes to be used as
signal sources, with such nodes not taking up any system resources during
their inactive periods.</li>
<li>Add <a href="http://www.w3.org/TR/webaudio/#DynamicLifetime">dynamic lifetime</a> support similar to native nodes, whereby unreferenced
"signal processor" script nodes driven by source nodes are automatically
released once the source node finishes, even if the source node is itself a
script node. To achieve this, the time at which the inputs cease must be
available as part of the event structure passed to the <code>onaudioprocess</code>
callback, so that the callback can begin any tail phase that it needs to
complete before it commits suicide.</li>
<li>Specify a convention and/or API to support tail times beyond
the time indicated in a stop(t) call or after its inputs have
been end-of-lifed.</li>
</ol>


<h3><a name="stellers-jsnode-model"></a>PS: Steller's jsnode model</h3>

<p>The <a href="https://github.com/srikumarks/steller">Steller</a> library features a <a href="https://github.com/srikumarks/steller/blob/experimental_buildsys/src/models/jsnode.js">jsnode</a> model that wraps the API's script
node into a node type that can be scheduled as discussed in this post. It also
adds some conveniences such as multiple inputs (albeit single channel), and
a-rate controllable and schedulable <a href="http://www.w3.org/TR/webaudio/#AudioParam">AudioParam</a> parameters. You can use
Steller's jsnode model like this -</p>

<p>``` html</p>

<script src="http://sriku.org/lib/steller/steller.min.js"></script>


<script>
    var sh = new org.anclab.steller.Scheduler(new webkitAudioContext);
    var jsn = sh.models.jsnode({
        numberOfInputs: 0,
        numberOfOutputs: 1,
        onaudioprocess: function (event) {
            // ...
            return toSamp - fromSamp;
        }});
    jsn.connect(AC.destination);
    sh.play(sh.fire(function (clock) {
        jsn.start(clock.t);
        jsn.stop(clock.t + 10.0);
    }));
</script>


<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A critique of Tuna]]></title>
    <link href="http://srikumarks.github.com/blog/2012/11/09/a-critique-of-tuna/"/>
    <updated>2012-11-09T00:00:00+05:30</updated>
    <id>http://srikumarks.github.com/blog/2012/11/09/a-critique-of-tuna</id>
    <content type="html"><![CDATA[<p>Google has open sourced the <a href="http://github.com/Dinahmoe/tuna">Tuna</a> set of effects used in their <a href="http://www.google.com/?q=jam+with+chrome">Jam with Chrome</a>
project. Here, I collect some thoughts about the code design decisions for their
effects framework, since I myself have written <a href="http://github.com/srikumarks/steller">Steller</a>.</p>

<!-- more -->


<h2>Parameters</h2>

<p>In Tuna, the effects module's parameters are presented to the API user as
object properties and implemented using getters and setters. This is obviously
simple from the perspective of a module user. However, it has several disadvantages -</p>

<p>If a module contains another module and you want to expose that parameter,
you're forced to write another getter/setter to handle the indirection. Such
parameters cannot be passed around "by reference". The only thing you can
do with them is to set/get their values. "By reference" passing is a simple
way to expose an internal module's parameters to the module user which is an
important kind of composability.</p>

<p>Owing to the getter/setter approach, meta information about parameters such as
their range, defaults, automation capabilities, etc. need to be stored elsewhere
in a "defaults" object, instead of being directly associated with them.</p>

<p>In some of the effects, some internal values and other parameters need to be
recomputed when a couple of parameters change. In this case, the code for
updating the dependent parameters is duplicated since it is not particularly
convenient to write a shared function local when defining parameters using
<code>Object.create</code> like this -</p>

<p>``` js</p>

<pre><code>//...
baseFrequency: {
    enumerable: true,
    get: function () {return this._baseFrequency},
    set: function (value) {
        this._baseFrequency = 50 * Math.pow(10, value * 2);
        this._excursionFrequency = Math.min(this.sampleRate / 2, this.baseFrequency * Math.pow(2, this._excursionOctaves));
        this.filterBp.frequency.value = this._baseFrequency + this._excursionFrequency * this._sweep;
        this.filterPeaking.frequency.value = this._baseFrequency + this._excursionFrequency * this._sweep;
    }
}, 
excursionOctaves: {
    enumerable: true,
    get: function () {return this._excursionOctaves},
    set: function (value) {
        this._excursionOctaves = value;
        this._excursionFrequency = Math.min(this.sampleRate / 2, this.baseFrequency * Math.pow(2, this._excursionOctaves));
        this.filterBp.frequency.value = this._baseFrequency + this._excursionFrequency * this._sweep;
        this.filterPeaking.frequency.value = this._baseFrequency + this._excursionFrequency * this._sweep;
    }
}, 
//...
</code></pre>

<p>```</p>

<p>A simpler way to solve this would be to have parameters be first class objects
that can be inspected, instead of just accessing and setting their values. Meta
data about them can travel along with them. In <a href="http://github.com/srikumarks/steller">Steller</a>, watcher functions can
be installed on parameters run code when the parameter's value changes.</p>

<h2>Inheritance using the <code>prototype</code> mechanism</h2>

<p>One of the code design choices that vastly complicates the code in this case
is the choice of using <code>prototype</code> based inheritance to define the properties
of instantiated effects modules. While this is common in the JS world,
in this case it deprives the programmer of a local context in which to hide
internal objects from the effects module's user and to write shared private
code like in the case above. Any potential loss of efficiency in not using
the prototype mechanism for this application is insignificant since object
creation is not the thing we should be optimising for.</p>

<p>The "define all methods and properties within the constructor function"
approach is much more suitable in this situation.</p>
]]></content>
  </entry>
  
</feed>
