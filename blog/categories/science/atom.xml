<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: science | Codaholic]]></title>
  <link href="http://srikumarks.github.com/blog/categories/science/atom.xml" rel="self"/>
  <link href="http://srikumarks.github.com/"/>
  <updated>2012-12-21T12:54:12+05:30</updated>
  <id>http://srikumarks.github.com/</id>
  <author>
    <name><![CDATA[Srikumar]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Newcomb's problem and quantum physics]]></title>
    <link href="http://srikumarks.github.com/blog/2011/05/07/newcombs-problem-and-quantum-physics/"/>
    <updated>2011-05-07T00:00:00+05:30</updated>
    <id>http://srikumarks.github.com/blog/2011/05/07/newcombs-problem-and-quantum-physics</id>
    <content type="html"><![CDATA[<p>How would <a href="http://lesswrong.com/lw/nc/newcombs_problem_and_regret_of_rationality/">Newcomb's problem</a> look like in the physical world, taking quantum
physics into account? Specifically, would Omega need to know quantum physics in
order to predict my decision on "to one box or not to one box"?</p>

<p>To simplify the picture, imagine that Omega has a variable with it that can be
either in the state A+B or B and which is expected to correlate with my
decision and therefore serves to "predict" me. Omega runs some physical process
to arrive at the contents of this variable. I'm assuming that "to predict"
means "to simulate" - i.e. Omega can predict me by running a simulation of me
(say using a universal quantum Turing machine) though that is not necessarily
the only way to do so. Given that we're in a quantum world, would Omega
actually need to simulate me in order to ensure a correlation between its
variable and my choice, potentially in another galaxy, of whether to pick A+B
or B?</p>

<p>Say <code>|Oab&gt;</code> and <code>|Ob&gt;</code> are the two eigenstates of Omega's variable (w.r.t.
some operator it has) and the box system in front of me similarly has two
eigenstates <code>|Cab&gt;</code> and <code>|Cb&gt;</code> ("C" for "choice") and my "action" is simply a
choice of measuring the box system in the state <code>|Cab&gt;</code> or in the state
<code>|Cb&gt;</code> and not a mixture of them.</p>

<p>If Omega sets up an EPR-like entanglement between its variable and the box
system of the form <code>m|Oab&gt;|Cab&gt; + n|Ob&gt;|Cb&gt;</code>, and then chooses to measure a
mixed state of its variable, say, <code>|Oab&gt;+|Ob&gt;</code>, it can bifurcate the universe.
Then, if I measure <code>|Cab&gt;</code> (i.e. choose A+B), I end up in the same universe as
the one in which Omega measured its variable to be <code>|Oab&gt;</code> and if I choose
<code>|Cb&gt;</code>, I end up in the same universe as the one in which Omega measured its
variable to be <code>|Ob&gt;</code>.  Therefore, if our two systems are entangled this way,
Omega wouldn't need to take any trouble to simulate me at all in order to
ensure its reputation of being a perfect predictor!</p>

<p>That is only as far as Omega's reputation for being a perfect predictor is
concerned. But hold on for a moment there. In this setup, the box system's
state is not disconnected from that of Omega's predictor variable even if Omega
has left the galaxy and yet Omega cannot causally influence it "contents". In
my thinking, this is an argument against the stance of the "causal decision
theorists" that whatever the contents of the box, it is "fixed" and therefore I
maximize my utility by picking A+B. This is now an argument for the one boxers
observing that Omega has shown a solid history of being right (i.e. Omega's
internal variable has always correlated with the choices of all the people
before), forming the simplest (?) explanation that Omega could be using quantum
entanglement to effect the correlation, and therefore choosing to one box so
that they end up in the universe with a million bucks instead of the one with a
thousand.</p>

<p>So, my final question is this - does knowledge of quantum physics resolve
Newcomb's problem in favour of the one boxers? If not, the arguments certainly
would be interesting to read :)</p>

<p>PS: I tried to post this on the Less Wrong site but my post isn't appearing in
the comments. So I'm just posting it here for starters.</p>
]]></content>
  </entry>
  
</feed>
